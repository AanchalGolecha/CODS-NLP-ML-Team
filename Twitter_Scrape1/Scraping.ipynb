{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT THE TWEET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=83.0.4103.97)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-204f30ae00bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Ana\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         \"\"\"\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Ana\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Ana\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=83.0.4103.97)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "link = 'https://t.co/WDn16d4Biz'\n",
    "driver = webdriver.Chrome(executable_path='C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe') #the path where chromedriver.exe is installed in your local system\n",
    "driver.get(link)\n",
    "time.sleep(10)\n",
    "elements = []\n",
    "for i in range(2, 4):\n",
    "    try:\n",
    "        elements.append(driver.find_elements_by_xpath('/html/body/div/div/div/div[2]/main/div/div/div/div/div/div/div/section/div/div/div/div[' + str(i) + ']/div/div/div/div/article/div/div[2]/div[2]/div[2]/div[1]/div/span'))\n",
    "    except:\n",
    "        continue\n",
    "for i in elements:\n",
    "    for j in i:\n",
    "        print(j.text)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM OF KARNATAKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Covid19 Bulletin: 10th June 2020\\n\\nTotal Conf...</td>\n",
       "      <td>2020-06-10 12:55:13</td>\n",
       "      <td>https://t.co/j7VAycMYe6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Covid19 Bulletin: 9th June 2020\\n\\nTotal Confi...</td>\n",
       "      <td>2020-06-09 13:54:48</td>\n",
       "      <td>https://t.co/i1OtZ8ufRp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Covid19 Bulletin: 8th June 2020\\n\\nTotal Confi...</td>\n",
       "      <td>2020-06-08 13:58:59</td>\n",
       "      <td>https://t.co/lbce11Oq0K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid19 Bulletin: 7th June 2020\\n\\nTotal Confi...</td>\n",
       "      <td>2020-06-07 13:12:09</td>\n",
       "      <td>https://t.co/qFmw7Fle0m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Covid19 Bulletin: 6th June 2020\\n\\nTotal Confi...</td>\n",
       "      <td>2020-06-06 13:42:42</td>\n",
       "      <td>https://t.co/ZHLi06IgwE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Covid19 Bulletin: 5th June 2020\\n\\nTotal Confi...</td>\n",
       "      <td>2020-06-05 12:52:38</td>\n",
       "      <td>https://t.co/PdGLQZGAqd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Covid19 Bulletin: 4th June 2020\\n\\nTotal Confi...</td>\n",
       "      <td>2020-06-04 13:44:03</td>\n",
       "      <td>https://t.co/DBRHwXaKvF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Covid19 Bulletin: 3rd June  2020\\n\\nTotal Conf...</td>\n",
       "      <td>2020-06-03 14:53:51</td>\n",
       "      <td>https://t.co/JfEjFq6mYg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Covid19 Bulletin: 2nd June  2020\\n\\nTotal Conf...</td>\n",
       "      <td>2020-06-02 16:02:02</td>\n",
       "      <td>https://t.co/4ecM35Byqv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Covid19 Bulletin: 1st June  2020\\n\\nTotal Conf...</td>\n",
       "      <td>2020-06-01 13:21:06</td>\n",
       "      <td>https://t.co/kGVEXwMRej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Covid19: Evening Bulletin, 31st May 2020\\n\\nTo...</td>\n",
       "      <td>2020-05-31 13:08:13</td>\n",
       "      <td>https://t.co/VqfqDT7EQg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Covid19: Evening Bulletin, 30th May 2020\\n\\nTo...</td>\n",
       "      <td>2020-05-30 12:11:16</td>\n",
       "      <td>https://t.co/kBEiIwkucy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Covid19: Evening Bulletin, 29th May 2020\\n\\nTo...</td>\n",
       "      <td>2020-05-29 12:33:15</td>\n",
       "      <td>https://t.co/5O8UtyVXrR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Covid19: Mid- Day  Bulletin\\n\\nTotal Confirmed...</td>\n",
       "      <td>2020-05-29 07:41:04</td>\n",
       "      <td>https://t.co/wYmPThyvV9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweets        Date Created  \\\n",
       "0   Covid19 Bulletin: 10th June 2020\\n\\nTotal Conf... 2020-06-10 12:55:13   \n",
       "1   Covid19 Bulletin: 9th June 2020\\n\\nTotal Confi... 2020-06-09 13:54:48   \n",
       "2   Covid19 Bulletin: 8th June 2020\\n\\nTotal Confi... 2020-06-08 13:58:59   \n",
       "3   Covid19 Bulletin: 7th June 2020\\n\\nTotal Confi... 2020-06-07 13:12:09   \n",
       "4   Covid19 Bulletin: 6th June 2020\\n\\nTotal Confi... 2020-06-06 13:42:42   \n",
       "5   Covid19 Bulletin: 5th June 2020\\n\\nTotal Confi... 2020-06-05 12:52:38   \n",
       "6   Covid19 Bulletin: 4th June 2020\\n\\nTotal Confi... 2020-06-04 13:44:03   \n",
       "7   Covid19 Bulletin: 3rd June  2020\\n\\nTotal Conf... 2020-06-03 14:53:51   \n",
       "8   Covid19 Bulletin: 2nd June  2020\\n\\nTotal Conf... 2020-06-02 16:02:02   \n",
       "9   Covid19 Bulletin: 1st June  2020\\n\\nTotal Conf... 2020-06-01 13:21:06   \n",
       "10  Covid19: Evening Bulletin, 31st May 2020\\n\\nTo... 2020-05-31 13:08:13   \n",
       "11  Covid19: Evening Bulletin, 30th May 2020\\n\\nTo... 2020-05-30 12:11:16   \n",
       "12  Covid19: Evening Bulletin, 29th May 2020\\n\\nTo... 2020-05-29 12:33:15   \n",
       "13  Covid19: Mid- Day  Bulletin\\n\\nTotal Confirmed... 2020-05-29 07:41:04   \n",
       "\n",
       "                        URL  \n",
       "0   https://t.co/j7VAycMYe6  \n",
       "1   https://t.co/i1OtZ8ufRp  \n",
       "2   https://t.co/lbce11Oq0K  \n",
       "3   https://t.co/qFmw7Fle0m  \n",
       "4   https://t.co/ZHLi06IgwE  \n",
       "5   https://t.co/PdGLQZGAqd  \n",
       "6   https://t.co/DBRHwXaKvF  \n",
       "7   https://t.co/JfEjFq6mYg  \n",
       "8   https://t.co/4ecM35Byqv  \n",
       "9   https://t.co/kGVEXwMRej  \n",
       "10  https://t.co/VqfqDT7EQg  \n",
       "11  https://t.co/kBEiIwkucy  \n",
       "12  https://t.co/5O8UtyVXrR  \n",
       "13  https://t.co/wYmPThyvV9  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whatever as wt\n",
    "from langdetect import detect\n",
    "from selenium import webdriver\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # # # CREATING THE DATA FRAME # # # # \n",
    "class TweetAnalyzer():\n",
    "    \n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "        df['Date Created'] = np.array([tweet.created_at for tweet in tweets])\n",
    "#         df[\"24H\"] = df[\"Date Created\"].apply(lambda x: 0 if (datetime.utcnow()-x)>timedelta(1) else 1)\n",
    "#         df.drop(columns=[\"Date Created\"],axis=1,inplace=True)\n",
    "#         df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "#         df.drop(df[df['likes']<=1000].index,inplace=True)\n",
    "#         df.drop(columns=\"likes\",inplace=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "# # # # FEATURE EXTRACTION # # # #\n",
    "class FilterData():\n",
    "    '''\n",
    "    Feature Extracting including removing Retweets, tweets which are in languages other than English and filtering out \n",
    "    tweets based on the text_query\n",
    "    '''\n",
    "    \n",
    "    def filter_RT():\n",
    "        df[\"Retweets\"] = df[\"Tweets\"].apply(lambda x: True if x[:2]==\"RT\" else False)\n",
    "        df.drop(df[df[\"Retweets\"]==True].index,inplace=True)\n",
    "        df.drop(columns=[\"Retweets\"],axis=1,inplace=True)\n",
    "        df.index = [i for i in range(df[\"Tweets\"].count())]\n",
    "    \n",
    "    def filter_tweets(t):\n",
    "        text_query = [\"Total Confirmed Cases: \"]\n",
    "        for i in df[\"Tweets\"]:\n",
    "            for j in text_query:\n",
    "                if j in i:\n",
    "                    t.append(i)\n",
    "        return t\n",
    "    \n",
    "    def filter_c_tweets(t):\n",
    "        df[\"C-Tweets\"] = df[\"Tweets\"].apply(lambda x: False if x in list(set(t)) else True)\n",
    "        df.drop(df[df[\"C-Tweets\"] == True].index,inplace=True)\n",
    "        df.drop(columns=\"C-Tweets\",axis=1,inplace=True)\n",
    "        df.index = [i for i in range(df[\"Tweets\"].count())]\n",
    "        \n",
    "    def filter_url(urls): \n",
    "        df[\"Tweets\"].apply(lambda x: urls.append(x[x.find(\"https://\"):]) if \"https://\" in x else urls.append(\"False\"))\n",
    "        return urls\n",
    "        \n",
    "    def replace_tweet(urls):\n",
    "            count = 0\n",
    "            for i in range(2):\n",
    "                driver = webdriver.Chrome(executable_path='C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe') #the path where chromedriver.exe is installed in your local system\n",
    "                if urls[i] != \"0\":\n",
    "                    driver.get(urls[i])\n",
    "#                     images(urls[i])\n",
    "                    time.sleep(10)\n",
    "                    elements = []\n",
    "                    for i in range(2, 4):\n",
    "                        try:\n",
    "                            elements.append(driver.find_elements_by_xpath('/html/body/div/div/div/div[2]/main/div/div/div/div/div/div/div/section/div/div/div/div[' + str(i) + ']/div/div/div/div/article/div/div[2]/div[2]/div[2]/div[1]/div/span'))\n",
    "                        except:\n",
    "                            continue \n",
    "                    for i in elements:\n",
    "                         for j in i:\n",
    "                                df.replace(to_replace = df[\"Tweets\"][count],value = j.text,inplace=True)\n",
    "                                count += 1\n",
    "            #                 print(type(j.text))\n",
    "                    driver.close()\n",
    "            df[\"Tweets\"]=df[\"Tweets\"].apply(lambda x: x.replace(x[:x.find(\"\\n\")],\"\"))\n",
    "#     def image(i_url):\n",
    "#         for i in df[\"URL\"]:\n",
    "#             driver = webdriver.Chrome(executable_path='C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe') #the path where chromedriver.exe is installed in your local system\n",
    "#             driver.get(link)\n",
    "#             time.sleep(10)\n",
    "#             elements = []\n",
    "#             images = []\n",
    "#             try:\n",
    "#                 elements.extend(driver.find_elements_by_class_name('css-9pa8cd'))\n",
    "#             except:\n",
    "#                 pass\n",
    "#             for i in elements:\n",
    "#                 images.append(i.get_attribute(\"src\")[3])\n",
    "#             #driver.get(images[3])\n",
    "#             #images[3] contains the relevant image\n",
    "#             driver.close()\n",
    "#         #     i_url.append(images[3])\n",
    "#             print(images)\n",
    "                      \n",
    "        \n",
    "# # # # MAIN # # # #\n",
    "if __name__ == '__main__':\n",
    "    t = []\n",
    "    urls = []\n",
    "    \n",
    "    screen_name = \"CMofKarnataka\"\n",
    "    \n",
    "    twitter_client = wt.TwitterClient()\n",
    "    \n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "\n",
    "    api = twitter_client.get_twitter_client_api()\n",
    "\n",
    "    tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    FilterData.filter_RT()\n",
    "#     FilterData.filter_lang()\n",
    "    FilterData.filter_tweets(t)\n",
    "    FilterData.filter_c_tweets(t)\n",
    "    FilterData.filter_url(urls)\n",
    "    FilterData.replace_tweet(urls)\n",
    "    df.to_csv(screen_name+'.csv')\n",
    "    df.to_json (screen_name + \".json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tweets\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "# from selenium import webdriver\n",
    "# import time\n",
    "urls = []\n",
    "df[\"Tweets\"][:4].apply(lambda x: urls.append(x[x.find(\"https://\"):]) if \"https://\" in x else urls.append(\"False\"))\n",
    "def images(urls):\n",
    "    elements = []\n",
    "    images = [\"name=360x360\"]\n",
    "    i_url = []\n",
    "    for i in urls:\n",
    "        if i!= \"False\":\n",
    "            link = i\n",
    "            driver = webdriver.Chrome(executable_path='C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe') #the path where chromedriver.exe is installed in your local system\n",
    "            driver.get(link)\n",
    "            time.sleep(10)\n",
    "            try:\n",
    "                elements.extend(driver.find_elements_by_class_name('css-9pa8cd'))\n",
    "            except:\n",
    "                pass\n",
    "    for i in elements:\n",
    "        images.append(i.get_attribute(\"src\"))\n",
    "    print(len(images))\n",
    "    driver.close()\n",
    "    df1 = pd.DataFrame({\"URL\":images})\n",
    "    df1[\"URL\"] = df1[\"URL\"].apply(lambda x: x if \"name=360x360\" in x else False)\n",
    "    df1.drop(df1[df1[\"URL\"]==False].index,inplace=True)\n",
    "    df1[\"Number\"] = [i+1 for i in range(df1[\"URL\"].count())]\n",
    "    df1 = df1[(df1[\"Number\"])%3 == 0]\n",
    "    df1.drop(\"Number\",axis=1,inplace=True)\n",
    "    df1.index = [i for i in range(df1[\"URL\"].count())]\n",
    "    df1.to_csv(\"images.csv\")\n",
    "images(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
